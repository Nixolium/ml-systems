{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e877ee",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "With a better understanding of data representation, let's now turn to preparing data for input into a machine learning pipeline. In the case of unsupervised learning, a simple matrix-level representation can suffice for input to machine learning models; we also need accompanying labels.\n",
    "\n",
    "Often, traffic capture datasets are accompanied by labels. These labels can tell us something about the accompanying data points (i.e., flows, packets) in the traffic, and can be used to train the model for future prediction.\n",
    "\n",
    "Automated tools exist for assigning labels to traffic flows, including [pcapML](https://nprint.github.io/pcapml/). Before we use those tools, we will do some automatic preparation and labeling from an existing dataset, a log4j trace from [malware traffic analysis](https://www.malware-traffic-analysis.net/2021/12/20/index.html) and a regular trace.\n",
    "\n",
    "You can use the NetML traffic library to generate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "caa27098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"scapy.runtime\").setLevel(logging.ERROR)\n",
    "\n",
    "from netml.pparser.parser import PCAP\n",
    "from netml.utils.tool import dump_data, load_data\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ee159",
   "metadata": {},
   "source": [
    "## Load the Packet Capture Files\n",
    "\n",
    "Load the Log4j and HTTP packet capture files and extract features from the flows. You can feel free to compute features manually, although it will likely be more convenient at this point to use the `netML` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34bdac14",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "hpcap = PCAP('data/http.pcap', flow_ptks_thres=2, verbose=10)\n",
    "lpcap = PCAP('data/log4j.pcap', flow_ptks_thres=2, verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838feb39",
   "metadata": {},
   "source": [
    "## Convert the Packet Capture Into Flows\n",
    "\n",
    "Find the function in `netml` that converts the pcap file into flows. Examing the resulting data structure. What does it contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "052ad290",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'_pcap2flows()' starts at 2023-10-18 16:04:19\n",
      "pcap_file: data/http.pcap\n",
      "ith_packets: 0\n",
      "ith_packets: 10000\n",
      "ith_packets: 20000\n",
      "len(flows): 593\n",
      "total number of flows: 593. Num of flows < 2 pkts: 300, and >=2 pkts: 293 without timeout splitting.\n",
      "kept flows: 293. Each of them has at least 2 pkts after timeout splitting.\n",
      "flow_durations.shape: (293, 1)\n",
      "        col_0\n",
      "count 293.000\n",
      "mean   11.629\n",
      "std    15.820\n",
      "min     0.000\n",
      "25%     0.076\n",
      "50%     0.455\n",
      "75%    20.097\n",
      "max    46.235\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 293 entries, 0 to 292\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   col_0   293 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 2.4 KB\n",
      "None\n",
      "0th_flow: len(pkts): 4\n",
      "After splitting flows, the number of subflows: 291 and each of them has at least 2 packets.\n",
      "'_pcap2flows()' ends at 2023-10-18 16:04:29 and takes 0.1692 mins.\n",
      "'_pcap2flows()' starts at 2023-10-18 16:04:29\n",
      "pcap_file: data/log4j.pcap\n",
      "ith_packets: 0\n",
      "ith_packets: 10000\n",
      "ith_packets: 20000\n",
      "ith_packets: 30000\n",
      "ith_packets: 40000\n",
      "ith_packets: 50000\n",
      "ith_packets: 60000\n",
      "ith_packets: 70000\n",
      "ith_packets: 80000\n",
      "len(flows): 44707\n",
      "total number of flows: 44707. Num of flows < 2 pkts: 39869, and >=2 pkts: 4838 without timeout splitting.\n",
      "kept flows: 4766. Each of them has at least 2 pkts after timeout splitting.\n",
      "flow_durations.shape: (4766, 1)\n",
      "          col_0\n",
      "count  4766.000\n",
      "mean     12.068\n",
      "std     191.592\n",
      "min       0.000\n",
      "25%       0.454\n",
      "50%       5.075\n",
      "75%       7.065\n",
      "max   12889.480\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4766 entries, 0 to 4765\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   col_0   4766 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 37.4 KB\n",
      "None\n",
      "0th_flow: len(pkts): 6\n",
      "1000th_flow: len(pkts): 5\n",
      "2000th_flow: len(pkts): 5\n",
      "3000th_flow: len(pkts): 6\n",
      "4000th_flow: len(pkts): 5\n",
      "After splitting flows, the number of subflows: 4795 and each of them has at least 2 packets.\n",
      "'_pcap2flows()' ends at 2023-10-18 16:04:53 and takes 0.388 mins.\n"
     ]
    }
   ],
   "source": [
    "# extract flows from pcap\n",
    "hpcap.pcap2flows()\n",
    "lpcap.pcap2flows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46c6a2",
   "metadata": {},
   "source": [
    "## Explore the Flows\n",
    "\n",
    "How many flows are in each of these pcaps? (Use the `netml` library output to determine the size of each data structure.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f4e3e52",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4795"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lpcap.flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "35b033be",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hpcap.flows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1cb95",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "## Extract Features for Each Dataset\n",
    "\n",
    "Extract features from each of the two datasets. You may want to use the `netml` library to generate features, although you can certainly compute your own. The [documentation](https://pypi.org/project/netml/) and [accompanying paper](https://arxiv.org/pdf/2006.16993.pdf) provide examples of features that you can try to extract. \n",
    "\n",
    "You can attempt to generate any of the following features available in the `netml` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2dad3dc3",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'_flow2features()' starts at 2023-10-18 16:04:53\n",
      "True\n",
      "'_flow2features()' ends at 2023-10-18 16:04:53 and takes 0.0017 mins.\n"
     ]
    }
   ],
   "source": [
    "# extract features from each flow via IAT\n",
    "lpcap.flow2features('IAT', fft=False, header=False)\n",
    "ld = pd.DataFrame(lpcap.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "82278ac9",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'_flow2features()' starts at 2023-10-18 16:04:53\n",
      "True\n",
      "'_flow2features()' ends at 2023-10-18 16:04:53 and takes 0.0007 mins.\n"
     ]
    }
   ],
   "source": [
    "# extract features from each flow via IAT\n",
    "hpcap.flow2features('IAT', fft=False, header=False)\n",
    "hd = pd.DataFrame(hpcap.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eddc7c",
   "metadata": {},
   "source": [
    "## Normalize the Shapes of Each Feature Set\n",
    "\n",
    "If you loaded the two pcaps with `netml` separately, the features will not be of the same dimension.  \n",
    "\n",
    "1. Adjust your data frames so that the two have the same number of columns.\n",
    "2. Merge (i.e., concatenate) the two data frames, but preserve the labels as a separate vector called \"target\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc6fabdc",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 92)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb075f16",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4795, 5)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7b16cc0",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 6)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hds = hd.loc[:,:5]\n",
    "hds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5f52303",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "hds['label'] = 0\n",
    "ld['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "884f0736",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>5.041</td>\n",
       "      <td>0.097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5.004</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.001</td>\n",
       "      <td>2.020</td>\n",
       "      <td>4.253</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4  label\n",
       "0 0.012 0.000 0.013 5.041 0.097      1\n",
       "1 0.012 0.001 5.004 0.146 0.000      1\n",
       "2 1.001 2.020 4.253 0.000 0.000      1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9f2a395",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037</td>\n",
       "      <td>30.003</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020</td>\n",
       "      <td>30.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.494</td>\n",
       "      <td>4.999</td>\n",
       "      <td>15.131</td>\n",
       "      <td>5.336</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2     3     4     5  label\n",
       "0  0.037 30.003  0.037 0.000 0.000 0.000      0\n",
       "1  0.020 30.020  0.020 0.000 0.000 0.000      0\n",
       "2 15.494  4.999 15.131 5.336 0.000 0.000      0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba76dd59",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>label</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>5.041</td>\n",
       "      <td>0.097</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5.004</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.001</td>\n",
       "      <td>2.020</td>\n",
       "      <td>4.253</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.816</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.019</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5086 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4  label     5\n",
       "0   0.012 0.000 0.013 5.041 0.097      1   NaN\n",
       "1   0.012 0.001 5.004 0.146 0.000      1   NaN\n",
       "2   1.001 2.020 4.253 0.000 0.000      1   NaN\n",
       "3   1.816 1.001 1.001 1.001 1.000      1   NaN\n",
       "4   0.000 0.000 0.000 0.000 0.000      1   NaN\n",
       "..    ...   ...   ...   ...   ...    ...   ...\n",
       "286 0.013 0.000 0.015 0.000 0.000      0 0.015\n",
       "287 0.013 0.000 0.001 0.016 0.000      0 0.000\n",
       "288 0.019 0.002 0.019 0.001 0.000      0 0.000\n",
       "289 0.024 0.001 0.000 0.000 0.012      0 0.032\n",
       "290 0.014 0.000 0.006 0.000 0.103      0 0.037\n",
       "\n",
       "[5086 rows x 7 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([ld,hds])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bcd475",
   "metadata": {},
   "source": [
    "## Try Your Data on a Model\n",
    "\n",
    "You should now have data that can be input into a model with scikit-learn. Import the scikit-learn package (`sklearn`) and a classification model of your choice to test that you can train your model with the above data. \n",
    "\n",
    "Hint: The function you want to call is `fit`.\n",
    "\n",
    "**Note:** If you plan to use a linear model such as logistic regression, your label should be a numerical value, and if the problem is a binary classification model, as in this case, then the appropriate label should be 0 and 1 for each respective class. (If you are using a tree-based model, then the labels could take any format.)\n",
    "\n",
    "(Note that we have not done anything here except train the model with all of the data. To evaluate the model, we will need to split the data into train and test sets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a88ceaaf",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c1fde8cc",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "features = data.loc[:,:4]\n",
    "targets = data['label']\n",
    "\n",
    "lr = LogisticRegression(random_state=0).fit(features, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f78849",
   "metadata": {},
   "source": [
    "## Test Your Trained Model\n",
    "\n",
    "We used the entire dataset to train the model in this example (no split), and so of course the model will be well-fit to all of the data. To simply test that your trained model works, call `predict` using a feature vector that you generate by hand (e.g., from scratch, using a random set of numbers, from another pcap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0363e508",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "results = []\n",
    "for i in range(100000):\n",
    "    test = np.random.rand(5).reshape(1,-1)\n",
    "    #print(test)\n",
    "    results.append(lr.predict(test))\n",
    "print(sum(results)/len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c96df8",
   "metadata": {},
   "source": [
    "## Bonus  \n",
    "\n",
    "Consider the following extensions to the above exercise:\n",
    "\n",
    "* Concatenate or combine multiple features (either from `netml` or some of your own) into the same feature representation.\n",
    "* Normalize your features so that they are in the same range (helpful for some models).\n",
    "\n",
    "The above exercise gives you an example of how to generate features from a packet capture, attach labels to the dataset, and train a model using the labeled data. \n",
    "\n",
    "## Looking Ahead\n",
    "\n",
    "Many other steps exist in the machine learning pipeline, including splitting the data into training and test sets, tuning model parameters, and evaluating the model. These will be the next steps we walk through."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
